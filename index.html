<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Chika Maduabuchi - AI/ML Researcher</title>
    <link rel="stylesheet" href="assets/css/main.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css">
    <link href="https://fonts.googleapis.com/css2?family=Merriweather:wght@400;700&display=swap" rel="stylesheet">
</head>
<body>
    <header class="masthead">
        <div class="container">
            <img src="assets/img/profile.jpg" alt="Chika Maduabuchi" class="profile-img">
            <div class="intro-text">
                <h1 class="masthead-heading">CHIKA MADUABUCHI</h1>
                <h2 class="masthead-subheading">AI/ML Researcher</h2>
                <div class="contact-info">
                    <a href="mailto:chikap421@gmail.com"><i class="fas fa-envelope"></i></a>
                    <a href="https://github.com/chikap421" target="_blank"><i class="fab fa-github"></i></a>
                    <a href="https://scholar.google.com/citations?hl=en&user=RpmxOsMAAAAJ&view_op=list_works&sortby=pubdate" target="_blank"><i class="fas fa-graduation-cap"></i></a>
                    <a href="https://www.linkedin.com/in/chika-maduabuchi-4796701b1/" target="_blank"><i class="fab fa-linkedin"></i></a>
                    <a href="https://twitter.com/chikamaduabuchi" target="_blank"><i class="fab fa-twitter"></i></a>
                </div>
                <div class="about-me">
                    <p>
                        I am an AI/ML researcher with a focus on Large Language Models (LLMs), Large Vision Models (LVMs), and Large Language-Vision Models (LLVMs). I am currently working on expanding the capability of LLMs for superior performance on low-resource languages at Ontario Tech University, where I am supervised by <a href="https://www.cs.toronto.edu/~ealee/public/" target="_blank">Professor Annie Lee</a>. My academic journey includes a Master of Science in Nuclear Science and Engineering from MIT, where I focused on Large Vision Models under the supervision of Professors <a href="https://web.mit.edu/nse/people/faculty/bucci.html" target="_blank">Matteo Bucci</a> and <a href="https://web.mit.edu/nse/people/faculty/jossou.html" target="_blank">Ericmoore Jossou</a>, and a Bachelor of Engineering in Mechanical Engineering from the University of Nigeria, with a focus on Applied Machine Learning. My research themes have included developing robust models for video segmentation and improving natural language processing for low-resource languages. My outcomes include creating state-of-the-art models like VideoSAM and AfriInstruct.
                    </p>
                </div>
            </div>
        </div>
    </header>
    <section id="news" class="news-section">
        <div class="container">
            <h2 class="section-heading">News</h2>
            <ul class="list-unstyled">
                <li>June 2024: Started collaboration with Ontario Tech University.</li>
                <li>May 2024: Presented at MIT AI Conference on VideoSAM model.</li>
                <li>April 2024: Published paper on AfriInstruct at ACL 2024.</li>
                <li>March 2024: Keynote speaker at African AI Summit.</li>
            </ul>
        </div>
    </section>
    <section id="publications" class="publications-section">
        <div class="container">
            <h2 class="section-heading">Publications</h2>
            <ul class="list-unstyled">
                <li>
                    <h4>VideoSAM: A Large Vision Foundation Model for High-Speed Video Segmentation</h4>
                    <p>Chika Maduabuchi, Ericmoore Jossou, Matteo Bucci, 17th Asian Conference on Computer Vision (ACCV 2024), submitted.</p>
                    <div class="publication-links">
                        <a href="#" target="_blank">Paper</a>
                        <a href="#" target="_blank">Code</a>
                        <a href="#" target="_blank">Dataset</a>
                    </div>
                </li>
                <li>
                    <h4>AfriInstruct: Instruction Tuning of African Languages for Diverse Tasks</h4>
                    <p>Kosei Uemura, Alex Pejovic, Mahe Chen, Chika Maduabuchi, Yifei Sun, En-Shiun Annie Lee, The 62nd Annual Meeting of the Association for Computational Linguistics (ACL 2024), submitted.</p>
                    <div class="publication-links">
                        <a href="#" target="_blank">Paper</a>
                        <a href="#" target="_blank">Code</a>
                        <a href="#" target="_blank">Dataset</a>
                    </div>
                </li>
                <li>
                    <h4>RAMD: Retrieval-Augmented Multimodal Diffusion for Efficient Text-to-Image Generation</h4>
                    <p>Chika Maduabuchi, 39th Annual AAAI Conference on Artificial Intelligence (AAAI 2025), In progress.</p>
                    <div class="publication-links">
                        <a href="#" target="_blank">Paper</a>
                        <a href="#" target="_blank">Code</a>
                        <a href="#" target="_blank">Dataset</a>
                    </div>
                </li>
            </ul>
        </div>
    </section>
</body>
</html>
