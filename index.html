<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Chika Maduabuchi - AI/ML Researcher</title>
    <link rel="stylesheet" href="assets/css/main.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css">
    <link href="https://fonts.googleapis.com/css2?family=Merriweather:wght@400;700&display=swap" rel="stylesheet">
</head>
<body>
    <header class="masthead">
        <div class="container">
            <img src="assets/img/Chika_Maduabuchi_PassportCarton.jpg" alt="Chika Maduabuchi" class="profile-img">
            <div class="intro-text">
                <h1 class="masthead-heading">CHIKA MADUABUCHI</h1>
                <h2 class="masthead-subheading">AI/ML Researcher</h2>
                <div class="contact-info">
                    <a href="mailto:chikap421@gmail.com"><i class="fas fa-envelope"></i></a>
                    <a href="https://github.com/chikap421" target="_blank"><i class="fab fa-github"></i></a>
                    <a href="https://scholar.google.com/citations?hl=en&user=RpmxOsMAAAAJ&view_op=list_works&sortby=pubdate" target="_blank"><i class="fas fa-graduation-cap"></i></a>
                    <a href="https://www.linkedin.com/in/chika-maduabuchi-4796701b1/" target="_blank"><i class="fab fa-linkedin"></i></a>
                    <a href="https://twitter.com/chikamaduabuchi" target="_blank"><i class="fab fa-twitter"></i></a>
                </div>
                <div class="about-me">
                    <p>
                        I am an AI/ML researcher with a focus on Large Language Models (LLMs), Large Vision Models (LVMs), and Large Language-Vision Models (LLVMs). I am currently working on expanding the capability of LLMs for superior performance on low-resource languages at Ontario Tech University, where I am supervised by <a class="prof-link" href="https://www.cs.toronto.edu/~ealee/public/" target="_blank">Professor Annie Lee</a>. 
                    </p>
                    <p>
                        My research journey includes an Engineering Masters Degree from MIT, where I focused on LVMs for video segmentation under the supervision of Professors <a class="prof-link" href="https://web.mit.edu/nse/people/faculty/bucci.html" target="_blank">Matteo Bucci</a> and <a class="prof-link" href="https://web.mit.edu/nse/people/faculty/jossou.html" target="_blank">Ericmoore Jossou</a>. Before this, I was an Applied Scientist at <a class="prof-link" href="https://acespedunn.edu.ng/" target="_blank">ACE-SPED</a>, where I led the AI for climate change initiative, accelerating clean energy research with ML. I obtained my Engineering Bachelor's degree from the University of Nigeria, where I focused on Applied Machine Learning. 
                    </p>
                    <p>
                        My research themes have included developing robust models for video segmentation and improving natural language processing for low-resource languages. My outcomes include creating state-of-the-art models like VideoSAM and AfriInstruct.
                    </p>
                </div>
            </div>
        </div>
    </header>
    <section id="news" class="news-section">
        <div class="container">
            <h2 class="section-heading">News</h2>
            <ul class="list-unstyled">
                <li>ðŸ“… <strong>July 2024:</strong> Working on the RAMD project, which focuses on retrieval-augmented multimodal diffusion for efficient text-to-image generation. Expected to be submitted to AAAI 25.</li>
                <li>ðŸ“… <strong>June 2024:</strong> Started a new research position at Ontario Tech University working under Professor Lee at the Lee Language Lab.</li>
                <li>ðŸ“… <strong>June 2024:</strong> Completed VideoSAM and AfriInstruct Projects and submitted to ACCV 24 and ACL 24, respectively. Hopeful for positive review outcome.</li>
                <li>ðŸ“… <strong>May 2024:</strong> Graduated from MIT with an Engineering Masters degree.</li>
                <li>ðŸ“… <strong>November 2024:</strong> Joined the MIT RED Lab as a Computer Vision Researcher.</li>
                <li>ðŸ“… <strong>September 2022:</strong> Started my Masters of Science Degree at MIT with a research focus on vision models for video segmentation.</li>
            </ul>
        </div>
    </section>
    <section id="publications" class="publications-section">
        <div class="container">
            <h2 class="section-heading">Publications</h2>
            <ol class="list-unstyled">
                <li>
                    <h4>[1]. VideoSAM: A Large Vision Foundation Model for High-Speed Video Segmentation</h4>
                    <p><strong>Chika Maduabuchi</strong>, Ericmoore Jossou, Matteo Bucci, 17th Asian Conference on Computer Vision (ACCV 2024), submitted.</p>
                    <div class="publication-links">
                        <a href="https://1drv.ms/f/s!Ao2gMD8JtNaEgZQlZJdSaqWMlQ18WQ?e=CF0V8z" target="_blank">Paper</a>
                        <a href="https://github.com/chikap421/videosam" target="_blank">Code</a>
                        <a href="#" target="_blank">Dataset</a>
                    </div>
                </li>
                <li>
                    <h4>[2]. AfriInstruct: Instruction Tuning of African Languages for Diverse Tasks</h4>
                    <p>Kosei Uemura, Alex Pejovic, Mahe Chen, <strong>Chika Maduabuchi</strong>, Yifei Sun, En-Shiun Annie Lee, The 62nd Annual Meeting of the Association for Computational Linguistics (ACL 2024), submitted.</p>
                    <div class="publication-links">
                        <a href="https://1drv.ms/f/s!Ao2gMD8JtNaEgZQk2FDr6TX2iY1XCQ?e=LQesaz" target="_blank">Paper</a>
                        <a href="https://github.com/AfricanLlama/AfricanNLP/tree/master" target="_blank">Code</a>
                        <a href="https://huggingface.co/datasets/llama-lang-adapt/AfriInstruct-Data" target="_blank">Dataset</a>
                    </div>
                </li>
                <li>
                    <h4>[3]. RAMD: Retrieval-Augmented Multimodal Diffusion for Efficient Text-to-Image Generation</h4>
                    <p><strong>Chika Maduabuchi</strong>, 39th Annual AAAI Conference on Artificial Intelligence (AAAI 2025), In progress.</p>
                    <div class="publication-links">
                        <a href="#" target="_blank">Paper</a>
                        <a href="#" target="_blank">Code</a>
                        <a href="#" target="_blank">Dataset</a>
                    </div>
                </li>
            </ol>
        </div>
    </section>
    <footer>
        <div class="container">
            <p>Last updated: June 2024</p>
        </div>
    </footer>
</body>
</html>
